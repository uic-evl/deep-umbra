{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "healthy-break",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import cv2\n",
    "import os\n",
    "import geopandas as gpd\n",
    "import dask_geopandas\n",
    "import numpy as np\n",
    "import multiprocessing\n",
    "from pyproj import Transformer\n",
    "from shapely.geometry import Polygon, box\n",
    "from tqdm.notebook import trange, tqdm\n",
    "from tqdm.dask import TqdmCallback\n",
    "from joblib import Parallel, delayed\n",
    "from dask import compute, delayed\n",
    "from dask.diagnostics import Profiler, ResourceProfiler, CacheProfiler, visualize\n",
    "from dask.distributed import performance_report\n",
    "\n",
    "transformer = Transformer.from_crs(3395, 4326)\n",
    "invtransformer = Transformer.from_crs(4326,3395)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "animal-duplicate",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def deg2num(lat_deg, lon_deg, zoom):\n",
    "    lat_rad = math.radians(lat_deg)\n",
    "    n = 2.0 ** zoom\n",
    "    xtile = ((lon_deg + 180.0) / 360.0 * n)\n",
    "    ytile = ((1.0 - math.asinh(math.tan(lat_rad)) / math.pi) / 2.0 * n)\n",
    "    return (xtile, ytile)\n",
    "\n",
    "def num2deg(xtile, ytile, zoom):\n",
    "    n = 2.0 ** zoom\n",
    "    lon_deg = xtile / n * 360.0 - 180.0\n",
    "    lat_rad = math.atan(math.sinh(math.pi * (1 - 2 * ytile / n)))\n",
    "    lat_deg = math.degrees(lat_rad)\n",
    "    return (lat_deg, lon_deg)\n",
    "\n",
    "def digital_elevation(gdf, cellsize):\n",
    "    bounds = gdf.total_bounds\n",
    "    bb0 = math.ceil(max(bounds[2], bounds[0]))\n",
    "    bb1 = math.floor(min(bounds[2], bounds[0]))\n",
    "    bb2 = math.ceil(max(bounds[3], bounds[1]))\n",
    "    bb3 = math.floor(min(bounds[3], bounds[1]))\n",
    "    \n",
    "    width = bb0 - bb1\n",
    "    height = bb2 - bb3\n",
    "    \n",
    "    grid = np.zeros((math.ceil(height/cellsize), math.ceil(width/cellsize)))\n",
    "    heightColumn = gdf.columns.get_loc(\"height\")\n",
    "    geomColumn = gdf.columns.get_loc(\"geometry\")\n",
    "    for x in range(bb1,bb0,cellsize):\n",
    "        for y in range(bb3,bb2,cellsize):\n",
    "            x0 = x\n",
    "            x1 = x+cellsize\n",
    "            y0 = y\n",
    "            y1 = y+cellsize\n",
    "            bbox = box(x0,y0,x1,y1)\n",
    "            intersected = gdf.geometry.sindex.intersection(bbox.bounds)\n",
    "            \n",
    "            for i in intersected:\n",
    "                buildingHeight = gdf.iat[i,heightColumn] # height -- iat is faster than iloc\n",
    "                buildingGeometry = gdf.iat[i,geomColumn] # geometry\n",
    "                val = (bbox.intersection(buildingGeometry).area / (bbox.area)) * buildingHeight\n",
    "                i, j = int((x-bb1)/cellsize), int((y-bb3)/cellsize)\n",
    "                grid[j][i] += val.sum()\n",
    "    grid = np.flipud(grid)\n",
    "    return grid\n",
    "\n",
    "def create_image(filtered, i, j, zoom, max_height, outputfolder):\n",
    "    dem = digital_elevation(filtered,10)\n",
    "    dem_bounds = filtered.total_bounds\n",
    "    dem_bb0 = transformer.transform(dem_bounds[0],dem_bounds[1])\n",
    "    dem_bb1 = transformer.transform(dem_bounds[2],dem_bounds[3])\n",
    "    dem_bb0 = deg2num(dem_bb0[0],dem_bb0[1],zoom)\n",
    "    dem_bb1 = deg2num(dem_bb1[0],dem_bb1[1],zoom)\n",
    "    dsize = (math.ceil(256*abs(dem_bb1[0]-dem_bb0[0])),math.ceil(256*abs(dem_bb1[1]-dem_bb0[1])))\n",
    "    dem = cv2.resize(dem, dsize=dsize)\n",
    "\n",
    "    startx = 256-256*(dem_bb0[0]%1)\n",
    "    endx = (-256*(dem_bb1[0]%1))\n",
    "    starty = 256-256*(dem_bb1[1]%1)\n",
    "    endy = (-256*(dem_bb0[1]%1))\n",
    "\n",
    "    values = dem[math.ceil(starty):math.floor(endy),math.ceil(startx):math.floor(endx)]\n",
    "    if values.shape[0] != 0 and values.shape[1] != 0:\n",
    "\n",
    "        values = cv2.resize(values, dsize=(256,256))\n",
    "        filename = '%s/%d/%d/%d.png'%(outputfolder,zoom,i,j)\n",
    "        directory = os.path.dirname(filename)\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "\n",
    "        success = cv2.imwrite(filename, 255.0 * (values / max_height))\n",
    "        if not success:\n",
    "            raise Exception(\"Could not write image\")\n",
    "#             print('done')\n",
    "#             aux = mpimg.imread(filename)\n",
    "#             print(aux.max()*max_height, values.max())\n",
    "\n",
    "def run(gdf, zoom, max_height, outputfolder):\n",
    "    bounds = gdf.total_bounds\n",
    "    lat0,lng0 = transformer.transform(bounds[0],bounds[1])\n",
    "    lat1,lng1 = transformer.transform(bounds[2],bounds[3])\n",
    "    coord0 = deg2num(lat0,lng0,zoom)\n",
    "    coord1 = deg2num(lat1,lng1,zoom)\n",
    "    bottomleft = [min(coord0[0],coord1[0]),min(coord0[1],coord1[1])]\n",
    "    topright = [max(coord0[0],coord1[0]),max(coord0[1],coord1[1])]\n",
    "\n",
    "    width = math.ceil(topright[0])-math.floor(bottomleft[0])\n",
    "    height = math.ceil(topright[1])-math.floor(bottomleft[1])\n",
    "\n",
    "    for i in range(math.floor(bottomleft[0]),math.ceil(topright[0])):\n",
    "        for j in range(math.floor(bottomleft[1]),math.ceil(topright[1])):\n",
    "            \n",
    "            bb0 = num2deg(i,j,zoom)\n",
    "            bb1 = num2deg(i+1,j+1,zoom)\n",
    "            bb0 = invtransformer.transform(bb0[0],bb0[1])\n",
    "            bb1 = invtransformer.transform(bb1[0],bb1[1])\n",
    "            filtered = gdf.cx[bb0[0]:bb1[0],bb0[1]:bb1[1]]\n",
    "            \n",
    "            if len(filtered) > 0:\n",
    "                create_image(filtered, i, j, zoom, max_height, outputfolder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "deluxe-hawaiian",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cities = ['nyc', 'dc', 'la', 'chi', 'bos']\n",
    "zooms = range(14,18)\n",
    "max_height = 550\n",
    "\n",
    "delayed_results = []\n",
    "for city in cities:\n",
    "    gdf = gpd.read_feather('data/osm/%s.feather'%city)\n",
    "    gdf = delayed(gdf)\n",
    "    for zoom in zooms:   \n",
    "        delayed_results.append(delayed(run)(gdf, zoom, max_height, 'data/heights/%s/'%city))\n",
    "compute(*delayed_results, scheduler='processes', num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7aac33c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from dask.distributed import Client\n",
    "# client = Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "812e0c5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Miniconda3\\envs\\geopandas\\lib\\site-packages\\dask\\base.py:1283: UserWarning: Running on a single-machine scheduler when a distributed client is active might lead to unexpected results.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32mC:\\Miniconda3\\envs\\geopandas\\lib\\site-packages\\dask\\multiprocessing.py:220\u001b[0m, in \u001b[0;36mget\u001b[1;34m(dsk, keys, num_workers, func_loads, func_dumps, optimize_graph, pool, chunksize, **kwargs)\u001b[0m\n\u001b[0;32m    218\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    219\u001b[0m     \u001b[38;5;66;03m# Run\u001b[39;00m\n\u001b[1;32m--> 220\u001b[0m     result \u001b[38;5;241m=\u001b[39m get_async(\n\u001b[0;32m    221\u001b[0m         pool\u001b[38;5;241m.\u001b[39msubmit,\n\u001b[0;32m    222\u001b[0m         pool\u001b[38;5;241m.\u001b[39m_max_workers,\n\u001b[0;32m    223\u001b[0m         dsk3,\n\u001b[0;32m    224\u001b[0m         keys,\n\u001b[0;32m    225\u001b[0m         get_id\u001b[38;5;241m=\u001b[39m_process_get_id,\n\u001b[0;32m    226\u001b[0m         dumps\u001b[38;5;241m=\u001b[39mdumps,\n\u001b[0;32m    227\u001b[0m         loads\u001b[38;5;241m=\u001b[39mloads,\n\u001b[0;32m    228\u001b[0m         pack_exception\u001b[38;5;241m=\u001b[39mpack_exception,\n\u001b[0;32m    229\u001b[0m         raise_exception\u001b[38;5;241m=\u001b[39mreraise,\n\u001b[0;32m    230\u001b[0m         chunksize\u001b[38;5;241m=\u001b[39mchunksize,\n\u001b[0;32m    231\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    232\u001b[0m     )\n\u001b[0;32m    233\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[1;32mC:\\Miniconda3\\envs\\geopandas\\lib\\site-packages\\dask\\local.py:497\u001b[0m, in \u001b[0;36mget_async\u001b[1;34m(submit, num_workers, dsk, result, cache, get_id, rerun_exceptions_locally, pack_exception, raise_exception, callbacks, dumps, loads, chunksize, **kwargs)\u001b[0m\n\u001b[0;32m    496\u001b[0m fire_tasks(chunksize)\n\u001b[1;32m--> 497\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, res_info, failed \u001b[38;5;129;01min\u001b[39;00m \u001b[43mqueue_get\u001b[49m\u001b[43m(\u001b[49m\u001b[43mqueue\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mresult():\n\u001b[0;32m    498\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m failed:\n",
      "File \u001b[1;32mC:\\Miniconda3\\envs\\geopandas\\lib\\site-packages\\dask\\local.py:127\u001b[0m, in \u001b[0;36mqueue_get\u001b[1;34m(q)\u001b[0m\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblock\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m Empty:\n",
      "File \u001b[1;32mC:\\Miniconda3\\envs\\geopandas\\lib\\queue.py:180\u001b[0m, in \u001b[0;36mQueue.get\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m    179\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[1;32m--> 180\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnot_empty\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mremaining\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    181\u001b[0m item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get()\n",
      "File \u001b[1;32mC:\\Miniconda3\\envs\\geopandas\\lib\\threading.py:316\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    315\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 316\u001b[0m     gotit \u001b[38;5;241m=\u001b[39m \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [21]\u001b[0m, in \u001b[0;36m<cell line: 8>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# with TqdmCallback(desc=\"compute\"):\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#     compute(*delayed_results, scheduler='processes')\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# with ProgressBar():\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m#         visualize([prof, rprof, cprof])\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m#         compute(*delayed_results, scheduler='processes', n_workers=8)\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m performance_report(filename\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdask-report.html\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m----> 9\u001b[0m     \u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdelayed_results\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mprocesses\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Miniconda3\\envs\\geopandas\\lib\\site-packages\\dask\\base.py:575\u001b[0m, in \u001b[0;36mcompute\u001b[1;34m(traverse, optimize_graph, scheduler, get, *args, **kwargs)\u001b[0m\n\u001b[0;32m    572\u001b[0m     keys\u001b[38;5;241m.\u001b[39mappend(x\u001b[38;5;241m.\u001b[39m__dask_keys__())\n\u001b[0;32m    573\u001b[0m     postcomputes\u001b[38;5;241m.\u001b[39mappend(x\u001b[38;5;241m.\u001b[39m__dask_postcompute__())\n\u001b[1;32m--> 575\u001b[0m results \u001b[38;5;241m=\u001b[39m schedule(dsk, keys, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    576\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m repack([f(r, \u001b[38;5;241m*\u001b[39ma) \u001b[38;5;28;01mfor\u001b[39;00m r, (f, a) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(results, postcomputes)])\n",
      "File \u001b[1;32mC:\\Miniconda3\\envs\\geopandas\\lib\\site-packages\\dask\\multiprocessing.py:235\u001b[0m, in \u001b[0;36mget\u001b[1;34m(dsk, keys, num_workers, func_loads, func_dumps, optimize_graph, pool, chunksize, **kwargs)\u001b[0m\n\u001b[0;32m    233\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    234\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m cleanup:\n\u001b[1;32m--> 235\u001b[0m         \u001b[43mpool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshutdown\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    236\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mC:\\Miniconda3\\envs\\geopandas\\lib\\concurrent\\futures\\process.py:740\u001b[0m, in \u001b[0;36mProcessPoolExecutor.shutdown\u001b[1;34m(self, wait, cancel_futures)\u001b[0m\n\u001b[0;32m    737\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_executor_manager_thread_wakeup\u001b[38;5;241m.\u001b[39mwakeup()\n\u001b[0;32m    739\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_executor_manager_thread \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m wait:\n\u001b[1;32m--> 740\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_executor_manager_thread\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    741\u001b[0m \u001b[38;5;66;03m# To reduce the risk of opening too many files, remove references to\u001b[39;00m\n\u001b[0;32m    742\u001b[0m \u001b[38;5;66;03m# objects that use file descriptors.\u001b[39;00m\n\u001b[0;32m    743\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_executor_manager_thread \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Miniconda3\\envs\\geopandas\\lib\\threading.py:1053\u001b[0m, in \u001b[0;36mThread.join\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m   1050\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot join current thread\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1052\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1053\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wait_for_tstate_lock\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1054\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1055\u001b[0m     \u001b[38;5;66;03m# the behavior of a negative timeout isn't documented, but\u001b[39;00m\n\u001b[0;32m   1056\u001b[0m     \u001b[38;5;66;03m# historically .join(timeout=x) for x<0 has acted as if timeout=0\u001b[39;00m\n\u001b[0;32m   1057\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait_for_tstate_lock(timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mmax\u001b[39m(timeout, \u001b[38;5;241m0\u001b[39m))\n",
      "File \u001b[1;32mC:\\Miniconda3\\envs\\geopandas\\lib\\threading.py:1073\u001b[0m, in \u001b[0;36mThread._wait_for_tstate_lock\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m   1070\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m   1072\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1073\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mlock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m   1074\u001b[0m         lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m   1075\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stop()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# with TqdmCallback(desc=\"compute\"):\n",
    "#     compute(*delayed_results, scheduler='processes')\n",
    "# with ProgressBar():\n",
    "#     compute(*delayed_results, scheduler='processes', n_workers=8)\n",
    "# with Profiler() as prof, ResourceProfiler() as rprof, CacheProfiler() as cprof:\n",
    "#         visualize([prof, rprof, cprof])\n",
    "#         compute(*delayed_results, scheduler='processes', n_workers=8)\n",
    "# with performance_report(filename=\"dask-report.html\"):\n",
    "#     compute(*delayed_results, scheduler='processes', num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "boring-drawing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cities = ['nyc', 'dc', 'la', 'chi', 'bos']\n",
    "# zooms = range(14,18)\n",
    "# max_height = 550\n",
    "\n",
    "# delayed_results = []\n",
    "# for city in cities:\n",
    "#     gdf = gpd.read_feather('data/osm/%s.feather'%city)\n",
    "#     for zoom in zooms:   \n",
    "#         run(gdf, zoom, max_height, 'data/heights/%s/'%city)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "polish-spouse",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %lprun -f digital_elevation run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
