{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59197f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "import dask.array as da\n",
    "\n",
    "import math\n",
    "import os\n",
    "import time\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from typing import Iterator\n",
    "\n",
    "import cv2\n",
    "import dask_geopandas as dgpd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pygeos.creation\n",
    "import pygeos.creation\n",
    "from geopandas import GeoDataFrame\n",
    "from pandas import Series\n",
    "from pyproj import Transformer\n",
    "from pathlib import Path\n",
    "\n",
    "from cutil import (\n",
    "    load_image,\n",
    "    deg2num,\n",
    "    nums2degs,\n",
    "    num2deg\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb54388",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tiles(gdf: GeoDataFrame, zoom: int) -> GeoDataFrame:\n",
    "    pw, ps, pe, pn = gdf.total_bounds\n",
    "\n",
    "    trans = Transformer.from_crs(gdf.crs, 4326, always_xy=True)\n",
    "    gw, gn = trans.transform(pw, pn)\n",
    "    ge, gs = trans.transform(pe, ps)\n",
    "\n",
    "    tw, tn = deg2num(gw, gn, zoom, always_xy=True)\n",
    "    te, ts = deg2num(ge, gs, zoom, always_xy=True)\n",
    "\n",
    "    # Just making sure that the tiles are actually north, west\n",
    "    tn, ts = min(tn, ts), max(tn, ts)\n",
    "    tw, te = min(tw, te), max(tw, te)\n",
    "\n",
    "    # np.ndarray indexing is [row, column], so I am using [north, west] to maintain that convention\n",
    "    # Convention: repeat rows, tile columns\n",
    "\n",
    "    # Slippy Tiles\n",
    "    tn = np.arange(tn, ts, dtype=np.uint64)  # xtile goes from n to s\n",
    "    tw = np.arange(tw, te, dtype=np.uint64)  # ytile goes from w to e\n",
    "\n",
    "    # Geographic\n",
    "    # Generate from northmost tiles and westmost tiles O(n) instead of all tiles O(n^2)\n",
    "    _, tgn = nums2degs(np.repeat(tw[0], len(tn)), tn, zoom, always_xy=True)\n",
    "    tgw, _ = nums2degs(tw, np.repeat(tn[0], len(tw)), zoom, always_xy=True)\n",
    "    tgs = np.append(\n",
    "        tgn[1:],\n",
    "        num2deg(tw[0], ts, zoom, always_xy=True)[1]\n",
    "    )\n",
    "    tge = np.append(\n",
    "        tgw[1:],\n",
    "        num2deg(te, tn[0], zoom, always_xy=True)[0]\n",
    "    )\n",
    "\n",
    "    # Projected\n",
    "    # Generate from northmost geographic and westmost geographic O(n) instead of all tiles O(n^2)\n",
    "    trans = Transformer.from_crs(4326, gdf.crs, always_xy=True)\n",
    "    _, tpn = trans.transform(np.repeat(tgw[0], len(tgn)), tgn)\n",
    "    tpw, _ = trans.transform(tgw, np.repeat(tgn[0], len(tgw)))\n",
    "    tps = np.append(\n",
    "        tpn[1:],\n",
    "        trans.transform(tgw[0], tgs[-1])[1]\n",
    "    )\n",
    "    tpe = np.append(\n",
    "        tpw[1:],\n",
    "        trans.transform(tge[-1], tgn[0])[0]\n",
    "    )\n",
    "\n",
    "    repeat_rows = len(tw)\n",
    "    tile_columns = len(tn)\n",
    "    tn = np.repeat(tn, repeat_rows)\n",
    "    tw = np.tile(tw, tile_columns)\n",
    "\n",
    "    tns = tn << 32\n",
    "    tntw = np.bitwise_or(tns, tw)\n",
    "    tntw = pd.Index(tntw, name='tntw', dtype=np.uint64)\n",
    "\n",
    "    tpw = np.tile(tpw, tile_columns)\n",
    "    tps = np.repeat(tps, repeat_rows)\n",
    "    tpe = np.tile(tpe, tile_columns)\n",
    "    tpn = np.repeat(tpn, repeat_rows)\n",
    "    geometry = pygeos.creation.box(tpw, tps, tpe, tpn)\n",
    "    h = (tps - tpn)\n",
    "    w = (tpe - tpw)\n",
    "\n",
    "    tiles = GeoDataFrame({\n",
    "        'tn': tn, 'tw': tw,\n",
    "        'tpn': tpn, 'tpw': tpw,\n",
    "        # 'tpw': tpw, 'tps': tps, 'tpe': tpe, 'tpn': tpn,\n",
    "        'h': h, 'w': w,\n",
    "        # }, geometry=geometry, crs=gdf.crs)\n",
    "    }, index=tntw, geometry=geometry, crs=gdf.crs)\n",
    "\n",
    "    itile, igdf = gdf.sindex.query_bulk(tiles.geometry)\n",
    "    loc = tiles.index[itile].unique()\n",
    "    tiles: GeoDataFrame = tiles.loc[loc]\n",
    "    # tiles = tiles.sort_values(['tn', 'tw'], ascending=True)\n",
    "    tiles = tiles.sort_index(ascending=True)\n",
    "    return tiles\n",
    "\n",
    "\n",
    "def get_cells(tiles: GeoDataFrame) -> tuple[dgpd.GeoDataFrame, int, int]:\n",
    "    # s, w, n, e = tiles.geometry.iloc[0].bounds\n",
    "    # rows = math.ceil(\n",
    "    #     abs(s - n) / cell_length\n",
    "    # )\n",
    "    # columns = math.ceil(\n",
    "    #     abs(e - w) / cell_length\n",
    "    # )\n",
    "    rows = 256\n",
    "    columns = 256\n",
    "    cells_per_tile = rows * columns\n",
    "    tile_count = len(tiles)\n",
    "    # TODO: everything 256x256\n",
    "\n",
    "    mb_per_tile = 8 * 8 * cells_per_tile / 1024 / 1024\n",
    "    tiles_per_chunk = math.floor(75 / mb_per_tile)\n",
    "    chunksize = cells_per_tile * tiles_per_chunk\n",
    "\n",
    "    dh = tiles['h'].values / rows\n",
    "    dw = tiles['w'].values / columns\n",
    "    if rows > 256:\n",
    "        raise ValueError(\n",
    "            f\"{rows=}>256. This means that the image will be downscaled, and cells require more than\"\n",
    "            f\" uint8. Increase zoom level.\"\n",
    "        )\n",
    "    cn = np.repeat(\n",
    "        np.arange(rows, dtype=np.uint8), columns,\n",
    "    )\n",
    "    cw = np.tile(\n",
    "        np.arange(columns, dtype=np.uint8), rows,\n",
    "    )\n",
    "    # This is the cause of the artifacts: cannot store 256 as np.uint8\n",
    "    cs = np.repeat(\n",
    "        np.arange(1, rows + 1, dtype=np.uint16), columns\n",
    "    )\n",
    "    ce = np.tile(\n",
    "        np.arange(1, columns + 1, dtype=np.uint16), rows\n",
    "    )\n",
    "    cnr = np.tile(cn, tile_count)\n",
    "    cwr = np.tile(cw, tile_count)\n",
    "    csr = np.tile(cs, tile_count)\n",
    "    cer = np.tile(ce, tile_count)\n",
    "\n",
    "    tpnr = da.from_array(\n",
    "        np.repeat(tiles['tpn'].values, cells_per_tile),\n",
    "        name='tpnr',\n",
    "        chunks=chunksize,\n",
    "    )\n",
    "    tpwr = da.from_array(\n",
    "        np.repeat(tiles['tpw'].values, cells_per_tile),\n",
    "        name='tpwr',\n",
    "        chunks=chunksize,\n",
    "    )\n",
    "    dhr = da.from_array(\n",
    "        np.repeat(dh, cells_per_tile),\n",
    "        name='dhr',\n",
    "        chunks=chunksize,\n",
    "    )\n",
    "    dwr = da.from_array(\n",
    "        np.repeat(dw, cells_per_tile),\n",
    "        name='dwr',\n",
    "        chunks=chunksize,\n",
    "    )\n",
    "\n",
    "    cpn = tpnr + (dhr * cnr)\n",
    "    cps = tpnr + (dhr * csr)\n",
    "    cpw = tpwr + (dwr * cwr)\n",
    "    cpe = tpwr + (dwr * cer)\n",
    "\n",
    "    tntw = dd.from_dask_array(da.from_array(\n",
    "        tiles.index.values.repeat(cells_per_tile),\n",
    "        chunksize,\n",
    "    ), columns='tntw')\n",
    "    area = np.abs(dh * dw)\n",
    "    arear = dd.from_dask_array(da.from_array(\n",
    "        np.repeat(area, cells_per_tile),\n",
    "        chunksize,\n",
    "    ), columns='area')\n",
    "\n",
    "    geometry = da.map_blocks(\n",
    "        pygeos.creation.box, cpw, cps, cpe, cpn,\n",
    "        dtype=object,\n",
    "    )\n",
    "    geometry = dd.from_dask_array(geometry, columns='geometry')\n",
    "    cn = dd.from_dask_array(da.from_array(\n",
    "        cnr, chunksize\n",
    "    ), 'cn')\n",
    "    cw = dd.from_dask_array(da.from_array(\n",
    "        cwr, chunksize,\n",
    "    ), 'cw')\n",
    "    cells = dd.concat([cn, cw, arear, geometry, tntw], axis=1)\n",
    "    cells: dgpd.GeoDataFrame = dgpd.from_dask_dataframe(cells)\n",
    "    cells.crs = tiles.crs\n",
    "\n",
    "    iloc = list(range(0, tile_count - 1, tiles_per_chunk))\n",
    "    iloc.append(tile_count - 1)\n",
    "    divisions = list(tiles.index[iloc])\n",
    "    cells = cells.set_index('tntw', sorted=True, divisions=divisions)\n",
    "    return cells, rows, columns\n",
    "\n",
    "\n",
    "def partition_mapping(cells: GeoDataFrame, directory: str, rows: int, columns: int, zoom: int, ):\n",
    "    # TODO: handle memory limit\n",
    "    weight: Series = cells.groupby(['tntw', 'cn', 'cw'], sort=False).weight.sum()\n",
    "    weight: Series = weight.astype(np.uint16)\n",
    "    groups = weight.groupby('tntw', sort=False).groups\n",
    "    tntw = np.fromiter(groups.keys(), dtype=np.uint64)\n",
    "    tn = np.bitwise_and(tntw, (2 ** 64 - (2 ** 32))) >> 32\n",
    "    tw = np.bitwise_and(tntw, (2 ** 32 - 1))\n",
    "\n",
    "    paths = [\n",
    "        os.path.join(directory, f'{zoom}/{tw_}/{tn_}.png')\n",
    "        for tn_, tw_ in zip(tn, tw)\n",
    "    ]\n",
    "    nodirs = (\n",
    "        dir\n",
    "        for path in paths\n",
    "        if not os.path.exists(dir := os.path.dirname(path))\n",
    "    )\n",
    "    subaggs: Iterator[Series] = (\n",
    "        weight.loc[loc]\n",
    "        for loc in groups.values()\n",
    "    )\n",
    "    images = (\n",
    "        load_image(\n",
    "            cn=subagg.index.get_level_values('cn').values,\n",
    "            cw=subagg.index.get_level_values('cw').values,\n",
    "            weights=subagg.values,\n",
    "            rows=rows,\n",
    "            columns=columns,\n",
    "        )\n",
    "        for subagg in subaggs\n",
    "    )\n",
    "    with ThreadPoolExecutor() as te:\n",
    "        te.map(os.makedirs, nodirs)\n",
    "    with ThreadPoolExecutor() as te:\n",
    "        te.map(cv2.imwrite, paths, images)\n",
    "\n",
    "\n",
    "def run(gdf: GeoDataFrame, zoom: int, max_height: float, outputfolder: str):\n",
    "    tiles = get_tiles(gdf, zoom)\n",
    "    cells, rows, columns = get_cells(tiles)\n",
    "\n",
    "    cells = cells.sjoin(gdf)\n",
    "    # TODO: Is this wasteful? Should I just call .intersection(gdf.loc[cells['index_right'], 'geometry'] ?\n",
    "    cells = cells.merge(\n",
    "        gdf[['geometry']], how='left', left_on='index_right', right_index=True, suffixes=('_cells', '_gdf'),\n",
    "    )\n",
    "    del gdf\n",
    "    cells: dgpd.GeoDataFrame = dgpd.from_dask_dataframe(cells, geometry='geometry_gdf')\n",
    "\n",
    "    cells['weight'] = (\n",
    "            dgpd.GeoSeries.intersection(cells['geometry_gdf'], cells['geometry_cells']).area\n",
    "            / cells['area']\n",
    "            * cells['height']\n",
    "            / max_height\n",
    "            * (2 ** 16 - 1)\n",
    "    )\n",
    "    \"\"\"\n",
    "    When generating the elevation maps, we assigned unitless weights to cells with the function:\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "#     warnings.filterwarnings('ignore', '.*empty Series.*')\n",
    "    meta = dd.utils.make_meta((None, None))\n",
    "#     warnings.filterwarnings('default', '.*empty Series.*')\n",
    "\n",
    "    cells = cells[['cn', 'cw', 'weight']]\n",
    "    cells.map_partitions(\n",
    "        partition_mapping,\n",
    "        directory=outputfolder,\n",
    "        rows=rows,\n",
    "        columns=columns,\n",
    "        zoom=zoom,\n",
    "        meta=meta,\n",
    "\n",
    "    ).compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80c0639",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = gpd.read_feather('data/osm/sp.feather')\n",
    "run(gdf, 16, 550, './data/heights_new/')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
