{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8922f7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pathlib\n",
    "import time\n",
    "import itertools\n",
    "import glob\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from IPython import display\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from deep_shadow import *\n",
    "from utils import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26c6caac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(tf.config.list_physical_devices('GPU'))\n",
    "print(tf.test.is_built_with_cuda())\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "342340f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cities = ['la','bos', 'dc', 'nyc','chi','sp', 'bue', 'joh', 'syd', 'tok', 'par', 'mex', 'sea', 'aus']\n",
    "dates = ['winter', 'spring', 'summer']\n",
    "zoom = 16\n",
    "shadow_path = 'data/shadows/'\n",
    "height_path = 'data/heights_new/'\n",
    "checkpoint_name = 'evaluation_new'\n",
    "checkpoint_path = 'training_checkpoints/%s'%(checkpoint_name)\n",
    "\n",
    "BATCH_SIZE = 1\n",
    "STEPS = 75000\n",
    "\n",
    "if not os.path.exists('results/'):\n",
    "    os.mkdir('results/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "298ff6f3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Case 1: Train on K-1 Cities, Test on 1 City\n",
    "# Training\n",
    "for city in cities:\n",
    "    train = cities[:]\n",
    "    train.remove(city)\n",
    "    \n",
    "    train_dataset = get_tiles(height_path, shadow_path, train, dates, zoom, 350) # 400 * 13 * 3\n",
    "    train_dataset = train_to_tensor(train_dataset, BATCH_SIZE)\n",
    "    \n",
    "    deep_shadow = DeepShadow(512,512)\n",
    "    deep_shadow.fit(checkpoint_path+'/'+city, train_dataset, None, STEPS)\n",
    "    \n",
    "    tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58702df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Case 1: Train on K-1 Cities, Test on 1 City\n",
    "# Testing\n",
    "for city in cities:\n",
    "    test = [city]\n",
    "    \n",
    "    deep_shadow = DeepShadow(512, 512)\n",
    "    deep_shadow.restore(checkpoint_path+'/'+city)\n",
    "    \n",
    "    test_dataset = get_tiles(height_path, shadow_path, test, dates, zoom, 1200)\n",
    "    test_dataset = test_to_tensor(test_dataset, BATCH_SIZE)\n",
    "    rmses, maes = get_metrics(test_dataset, deep_shadow.generator)\n",
    "        \n",
    "    print('\\nCity %s rmse: %.2f, mae: %.2f'%(city, np.average(rmses), np.average(maes)))\n",
    "    df = pd.DataFrame({'rmse': rmses, 'mae': maes})\n",
    "    \n",
    "    filepath = 'results/%s-%d/%s.csv'%(checkpoint_name, zoom, city)\n",
    "    if not os.path.exists(os.path.dirname(filepath)):\n",
    "        os.mkdir(os.path.dirname(filepath))\n",
    "    \n",
    "    df.to_csv(filepath, index=False, header=True)\n",
    "    \n",
    "    tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367603b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Case 2: Train-Test on All Cities (5 Fold Cross Validation)\n",
    "all_dataset = get_tiles(height_path, shadow_path, cities, dates, zoom, 400) \n",
    "all_dataset = np.array(all_dataset)\n",
    "\n",
    "kf = KFold(n_splits=5, random_state=42, shuffle=True)\n",
    "\n",
    "fold = 0\n",
    "for train_index, test_index in kf.split(all_dataset):\n",
    "\n",
    "    train_dataset = all_dataset[train_index]\n",
    "    train_dataset = train_to_tensor(train_dataset, BATCH_SIZE)\n",
    "    \n",
    "    deep_shadow = DeepShadow(512, 512)\n",
    "    deep_shadow.fit(checkpoint_path+'/fold_'+str(fold), train_dataset, None, STEPS)\n",
    "    \n",
    "    test_dataset = all_dataset[test_index]\n",
    "    test_dataset = test_to_tensor(test_dataset, BATCH_SIZE)\n",
    "    rmses, maes = get_metrics(test_dataset, deep_shadow.generator)\n",
    "    \n",
    "    print('\\nFold: %d rmse: %.2f mae: %.2f '%(fold, np.average(rmses), np.average(maes)))\n",
    "    df = pd.DataFrame({'rmse': rmses, 'mae': maes})\n",
    "    \n",
    "    filepath = 'results/%s-%d/fold_%d.csv'%(checkpoint_name, zoom, fold)\n",
    "    if not os.path.exists(os.path.dirname(filepath)):\n",
    "        os.mkdir(os.path.dirname(filepath))\n",
    "    \n",
    "    df.to_csv(filepath, index=False, header=True)\n",
    "    \n",
    "    fold+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "67393255",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for 1000 steps: 60.65 sec\n",
      "\n",
      "Step: 74k\n",
      "....................................................................................................\n",
      "Fold: 4 rmse: 0.06 mae: 0.03 mses: 0.01\n"
     ]
    }
   ],
   "source": [
    "# Case 3: Uniform Distribution of Latitudes (5 Fold Cross Validation)\n",
    "# Training\n",
    "# Paper\n",
    "cities = ['aus', 'par', 'syd', 'sp', 'mex', 'la', 'chi']\n",
    "\n",
    "all_dataset = get_tiles(height_path, shadow_path, cities, dates, zoom, 750) \n",
    "all_dataset = np.array(all_dataset)\n",
    "\n",
    "kf = KFold(n_splits=5, random_state=42, shuffle=True)\n",
    "\n",
    "fold = 0\n",
    "for train_index, test_index in kf.split(all_dataset):\n",
    "    \n",
    "    train_dataset = all_dataset[train_index]\n",
    "    train_dataset = train_to_tensor(train_dataset, BATCH_SIZE)\n",
    "    \n",
    "    deep_shadow = DeepShadow(512, 512)\n",
    "    deep_shadow.fit(checkpoint_path+'/uniform_fold_'+str(fold), train_dataset, None, STEPS)\n",
    "    \n",
    "    test_dataset = all_dataset[test_index]\n",
    "    test_dataset = test_to_tensor(test_dataset, BATCH_SIZE)\n",
    "    rmses, maes, mses = get_metrics(test_dataset, deep_shadow.generator)\n",
    "    \n",
    "    print('\\nFold: %d rmse: %.2f mae: %.2f mses: %.2f'%(fold, np.average(rmses), np.average(maes), np.average(mses)))\n",
    "    df = pd.DataFrame({'rmse': rmses, 'mae': maes, 'mses': mses})\n",
    "    \n",
    "    filepath = 'results/%s-%d/uniform_fold_%d.csv'%(checkpoint_name, zoom, fold)\n",
    "    if not os.path.exists(os.path.dirname(filepath)):\n",
    "        os.mkdir(os.path.dirname(filepath))\n",
    "    \n",
    "    df.to_csv(filepath, index=False, header=True)\n",
    "    \n",
    "    fold+=1\n",
    "    \n",
    "    tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6215fbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for 1000 steps: 63.88 sec\n",
      "\n",
      "Step: 74k\n",
      "...................................................................................................."
     ]
    }
   ],
   "source": [
    "# Case 4: Uniform Distribution of Latitudes\n",
    "# Training\n",
    "# Paper\n",
    "train_cities = ['aus', 'par', 'syd', 'sp', 'mex', 'la', 'chi']\n",
    "test_cities = ['dc', 'nyc', 'joh', 'bue', 'bos', 'sea', 'tok']\n",
    "\n",
    "train_dataset = get_tiles(height_path, shadow_path, train_cities, dates, zoom, 750)\n",
    "train_dataset = train_to_tensor(train_dataset, BATCH_SIZE)\n",
    "\n",
    "deep_shadow = DeepShadow(512,512)\n",
    "deep_shadow.fit(checkpoint_path+'/uniform_cities', train_dataset, None, STEPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93f4a211",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "City dc rmse: 0.09 mae: 0.03 mses: 0.01\n",
      "\n",
      "City nyc rmse: 0.09 mae: 0.04 mses: 0.01\n",
      "\n",
      "City joh rmse: 0.03 mae: 0.01 mses: 0.00\n",
      "\n",
      "City bue rmse: 0.05 mae: 0.02 mses: 0.00\n",
      "\n",
      "City bos rmse: 0.08 mae: 0.03 mses: 0.01\n",
      "\n",
      "City sea rmse: 0.07 mae: 0.04 mses: 0.01\n",
      "\n",
      "City tok rmse: 0.09 mae: 0.05 mses: 0.01\n"
     ]
    }
   ],
   "source": [
    "# Case 4: Uniform Distribution of Latitudes\n",
    "# Testing\n",
    "# Paper\n",
    "for city in test_cities:\n",
    "    test = [city]\n",
    "    \n",
    "    deep_shadow = DeepShadow(512, 512)\n",
    "    deep_shadow.restore(checkpoint_path+'/uniform_cities')\n",
    "    \n",
    "    test_dataset = get_tiles(height_path, shadow_path, test, dates, zoom, 750)\n",
    "    test_dataset = test_to_tensor(test_dataset, BATCH_SIZE)\n",
    "    rmses, maes, mses = get_metrics(test_dataset, deep_shadow.generator)\n",
    "    \n",
    "    print('\\nCity %s rmse: %.2f mae: %.2f mses: %.2f'%(city, np.average(rmses), np.average(maes), np.average(mses)))\n",
    "    df = pd.DataFrame({'rmse': rmses, 'mae': maes, 'mses': mses})\n",
    "    \n",
    "    filepath = 'results/%s-%d/uniform_%s.csv'%(checkpoint_name, zoom, city)\n",
    "    if not os.path.exists(os.path.dirname(filepath)):\n",
    "        os.mkdir(os.path.dirname(filepath))\n",
    "    \n",
    "    df.to_csv(filepath, index=False, header=True)\n",
    "    \n",
    "    tf.keras.backend.clear_session()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
