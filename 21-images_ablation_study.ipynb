{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython import display\n",
    "import datetime\n",
    "import time\n",
    "\n",
    "import glob\n",
    "import os\n",
    "import cv2\n",
    "import tqdm\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "from tqdm.notebook import trange, tqdm\n",
    "\n",
    "from utils import *\n",
    "from deep_shadow import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25edeca6946d41999696d19f592cfe02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# % bos 19832 24240 summer\n",
    "# % bue 22127 39476 spring\n",
    "# % dc 18730 25074 spring\n",
    "# % joh 37872 37714 winter\n",
    "# % joh 37873 37713 spring\n",
    "# % sea 10496 22885 winter\n",
    "# % sea 10497 22885 winter\n",
    "# % sea 10497 22887 summer\n",
    "# % tok 58211 25805 winter\n",
    "\n",
    "colors = [(1, 1, 1), (254/255,204/255,92/255), (253/255,141/255,60/255), (240/255,59/255,32/255), (189/255,0,38/255)]\n",
    "_cmap = LinearSegmentedColormap.from_list('colorscale', colors, N=100)\n",
    "\n",
    "# if not exists create folders like ablation_study/bos_19832_24240_summer\n",
    "ablation = [['bos', 19832, 24240, 'summer'], ['bue', 22127, 39476, 'spring'], ['dc', 18730, 25074, 'spring'], ['joh', 37872, 37714, 'winter'], \n",
    "            ['joh', 37873, 37713, 'spring'], ['sea', 10496, 22885, 'winter'], ['sea', 10497, 22885, 'winter'], ['sea', 10497, 22887, 'summer'], ['tok', 58211, 25805, 'winter']]\n",
    "\n",
    "# with tqdm\n",
    "# for i in range(len(ablation)):\n",
    "for i in tqdm(range(len(ablation))):\n",
    "    if not os.path.exists('data/ablation_study/%s_%d_%d_%s/'%(ablation[i][0], ablation[i][1], ablation[i][2], ablation[i][3])):\n",
    "        os.makedirs('data/ablation_study/%s_%d_%d_%s/'%(ablation[i][0], ablation[i][1], ablation[i][2], ablation[i][3]))\n",
    "\n",
    "    img = cv2.imread(\"data\\\\shadows\\\\%s-%s\\\\16\\\\%d\\\\%d.png\"%(ablation[i][0], ablation[i][3], ablation[i][1], ablation[i][2]), cv2.IMREAD_GRAYSCALE)\n",
    "    height = cv2.imread(\"data\\\\heights_new\\\\%s\\\\16\\\\%d\\\\%d.png\"%(ablation[i][0], ablation[i][1], ablation[i][2]), cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    img = np.where(height > 0, 0, img)\n",
    "\n",
    "    plt.axis('off')\n",
    "    plt.imshow(img, cmap=_cmap);\n",
    "\n",
    "    plt.savefig('data/ablation_study/%s_%d_%d_%s/ground_truth.png'%(ablation[i][0], ablation[i][1], ablation[i][2], ablation[i][3]), bbox_inches='tight', pad_inches = 0)\n",
    "    plt.close();\n",
    "\n",
    "    saved_models = ['l1', 'l1_smooth', 'l2', 'ssim_l1', 'ssim_l1_smooth', 'ssim_sobel_plus_l1', 'ssim_with_sobel']\n",
    "    loss_functions = [[l1_loss], [l1_smooth_loss], [l2_loss], [ssim_loss, l1_loss], [ssim_loss, l1_smooth_loss], [ssim_loss, l1_loss, sobel_loss], [ssim_loss, sobel_loss]]\n",
    "\n",
    "    for j in range(len(saved_models)):\n",
    "        tf.keras.backend.clear_session()\n",
    "        down_stack, up_stack = get_generator_arch('resnet9', attn=False)\n",
    "        deep_shadow = DeepShadow(512, 512, down_stack, up_stack, latitude=True, date=True, loss_funcs=loss_functions[j], type='resnet9', attention=False)\n",
    "        deep_shadow.restore('training_checkpoints_new/uniform_cities_resnet_wo_attn__%s'%saved_models[j])\n",
    "\n",
    "        height, pred = predict_shadow(deep_shadow.generator, 'data/heights_new/', ablation[i][0], ablation[i][3], 16, ablation[i][1], ablation[i][2], lat=True, dat=True)\n",
    "        pred = np.where(height > 0, -1, pred)\n",
    "\n",
    "        plt.axis('off')\n",
    "        plt.imshow(pred, cmap=_cmap);\n",
    "\n",
    "        plt.savefig('data/ablation_study/%s_%d_%d_%s/%s.png'%(ablation[i][0], ablation[i][1], ablation[i][2], ablation[i][3], saved_models[j]), bbox_inches='tight', pad_inches = 0)\n",
    "        plt.close();\n",
    "        test_on_image(deep_shadow.generator, 'data/heights_new/', 'data/shadows/', ablation[i][0], ablation[i][3], 16, ablation[i][1], ablation[i][2], lat=True, dat=True,\n",
    "                      path = 'data/ablation_study/%s_%d_%d_%s/%s_metrics.png'%(ablation[i][0], ablation[i][1], ablation[i][2], ablation[i][3], saved_models[j]),\n",
    "                    save=True)\n",
    "    \n",
    "    # *** #\n",
    "\n",
    "    tf.keras.backend.clear_session()\n",
    "    down_stack, up_stack = get_generator_arch('unet', attn=False)\n",
    "    deep_shadow = DeepShadow(512, 512, down_stack, up_stack, latitude=True, date=True, loss_funcs=[l1_loss], type='unet', attention=False)\n",
    "    deep_shadow.restore('training_checkpoints_new/uniform_cities_unet_wo_attn__l1')\n",
    "\n",
    "    height, pred = predict_shadow(deep_shadow.generator, 'data/heights_new/', ablation[i][0], ablation[i][3], 16, ablation[i][1], ablation[i][2], lat=True, dat=True)\n",
    "    pred = np.where(height > 0, -1, pred)\n",
    "    \n",
    "    plt.axis('off')\n",
    "    plt.imshow(pred, cmap=_cmap);\n",
    "\n",
    "    plt.savefig('data/ablation_study/%s_%d_%d_%s/unet_l1.png'%(ablation[i][0], ablation[i][1], ablation[i][2], ablation[i][3]), bbox_inches='tight', pad_inches = 0)\n",
    "    plt.close();\n",
    "\n",
    "    test_on_image(deep_shadow.generator, 'data/heights_new/', 'data/shadows/', ablation[i][0], ablation[i][3], 16, ablation[i][1], ablation[i][2], lat=True, dat=True,\n",
    "                  path = 'data/ablation_study/%s_%d_%d_%s/unet_l1_metrics.png'%(ablation[i][0], ablation[i][1], ablation[i][2], ablation[i][3]),\n",
    "                save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "shadow_path = 'data/shadows/'\n",
    "height_path = 'data/heights_new/'\n",
    "files = glob.glob('tile_heights/*.csv')\n",
    "\n",
    "def get_generator(_loss_functions, _saved_model, gen_arch='resnet9'):\n",
    "    tf.keras.backend.clear_session()\n",
    "    down_stack, up_stack = get_generator_arch(gen_arch, attn=False)\n",
    "    deep_shadow = DeepShadow(512, 512, down_stack, up_stack, latitude=True, date=True, loss_funcs=_loss_functions, type=gen_arch, attention=False)\n",
    "    deep_shadow.restore('training_checkpoints_new/%s'%_saved_model)\n",
    "\n",
    "    return deep_shadow.generator\n",
    "\n",
    "def get_rmse_list(tiles, gen, city, shadow_path, height_path):\n",
    "    rmses = []\n",
    "    for index, row in tqdm(tiles.iterrows(), total=tiles.shape[0], leave=False):\n",
    "        # get i, j\n",
    "        i = int(row['i'])\n",
    "        j = int(row['j'])\n",
    "\n",
    "        seasons = ['summer', 'winter', 'spring']\n",
    "        rmse = 0\n",
    "        for season in seasons:\n",
    "\n",
    "            # generator, height_path, city, date, zoom, i, j, lat=True, dat=True\n",
    "            height, pred = predict_shadow(gen, 'data/heights_new/', city, season, 16, i, j, lat=True, dat=True)\n",
    "            pred = np.where(height > 0, -1, pred)\n",
    "\n",
    "            gt = load_ground_truth(height, shadow_path, city, season, 16, i, j)\n",
    "            gt = np.where(height > 0, -1, gt)\n",
    "\n",
    "            pred = pred*0.5 + 0.5\n",
    "            gt = gt*0.5 + 0.5\n",
    "\n",
    "            rmse += np.sqrt(np.mean((pred - gt)**2))\n",
    "                    \n",
    "        rmse /= 3\n",
    "        rmses.append(rmse)\n",
    "\n",
    "    return rmses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f983d20be6894fe484997117f8c15a23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2f0034b88b3457ebef14e2db8ca33d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1340 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb338144bc1c4f0d94b6887b0277ba23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1037 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "daf1f984d66d4b2e9a1414a348275843",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1536 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b13cb480fcf44888ca442b245bcf1fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1990 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e615966c5886415788b3ca7d046b3dec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3742 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24ef0aee0aa94834a3668ceed43cc2bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1203 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_cities = ['dc', 'nyc', 'joh', 'bue', 'bos', 'sea', 'tok']\n",
    "\n",
    "for file in tqdm(files, total=len(files), leave=False):\n",
    "    file = file.replace('\\\\','/')\n",
    "    tiles = pd.read_csv(file)\n",
    "    city = file.split('/')[-1].split('.')[0].split('-')[0]\n",
    "\n",
    "    if city not in test_cities:\n",
    "        continue\n",
    "\n",
    "    # print(city)\n",
    "\n",
    "    # saved_models = ['l2', 'ssim_l1', 'ssim_with_sobel']\n",
    "    # loss_functions = [[l2_loss], [ssim_loss, l1_loss], [ssim_loss, sobel_loss]]\n",
    "\n",
    "\n",
    "    # for k in tqdm(range(len(saved_models))):\n",
    "    #     _saved_model = 'uniform_cities_resnet_wo_attn__%s'%saved_models[k]\n",
    "    #     gen = get_generator(loss_functions[k], _saved_model, gen_arch='resnet9')\n",
    "\n",
    "    #     rmses = get_rmse_list(tiles, gen, city, shadow_path, height_path)\n",
    "        \n",
    "    #     # print(rmses)\n",
    "    #     tiles['%s'%saved_models[k]] = rmses\n",
    "        \n",
    "    #     tiles.to_csv(file, index=False)\n",
    "\n",
    "    # gen = get_generator([l1_loss], 'uniform_cities_unet_wo_attn__l1', gen_arch='unet')\n",
    "    # rmses = get_rmse_list(tiles, gen, city, shadow_path, height_path)\n",
    "    # tiles['unet_l1'] = rmses\n",
    "    # tiles.to_csv(file, index=False)\n",
    "\n",
    "    # gen = get_generator([l1_loss], 'uniform_cities_resnet_wo_attn__l1', gen_arch='resnet9')\n",
    "    # rmses = get_rmse_list(tiles, gen, city, shadow_path, height_path)\n",
    "    # tiles['resnet_l1'] = rmses\n",
    "    # tiles.to_csv(file, index=False)\n",
    "\n",
    "    gen = get_generator([l1_loss], 'uniform_cities_resnet_wo_attn__ssim_sobel_plus_l1', gen_arch='resnet9')\n",
    "    rmses = get_rmse_list(tiles, gen, city, shadow_path, height_path)\n",
    "    tiles['resnet_ssim_sobel_l1'] = rmses\n",
    "    tiles.to_csv(file, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
