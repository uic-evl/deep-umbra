{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython import display\n",
    "import datetime\n",
    "import time\n",
    "\n",
    "import glob\n",
    "import os\n",
    "import cv2\n",
    "import tqdm\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "from tqdm.notebook import trange, tqdm\n",
    "\n",
    "from utils import *\n",
    "from deep_shadow import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25edeca6946d41999696d19f592cfe02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# % bos 19832 24240 summer\n",
    "# % bue 22127 39476 spring\n",
    "# % dc 18730 25074 spring\n",
    "# % joh 37872 37714 winter\n",
    "# % joh 37873 37713 spring\n",
    "# % sea 10496 22885 winter\n",
    "# % sea 10497 22885 winter\n",
    "# % sea 10497 22887 summer\n",
    "# % tok 58211 25805 winter\n",
    "\n",
    "colors = [(1, 1, 1), (254/255,204/255,92/255), (253/255,141/255,60/255), (240/255,59/255,32/255), (189/255,0,38/255)]\n",
    "_cmap = LinearSegmentedColormap.from_list('colorscale', colors, N=100)\n",
    "\n",
    "# if not exists create folders like ablation_study/bos_19832_24240_summer\n",
    "ablation = [['bos', 19832, 24240, 'summer'], ['bue', 22127, 39476, 'spring'], ['dc', 18730, 25074, 'spring'], ['joh', 37872, 37714, 'winter'], \n",
    "            ['joh', 37873, 37713, 'spring'], ['sea', 10496, 22885, 'winter'], ['sea', 10497, 22885, 'winter'], ['sea', 10497, 22887, 'summer'], ['tok', 58211, 25805, 'winter']]\n",
    "\n",
    "# with tqdm\n",
    "# for i in range(len(ablation)):\n",
    "for i in tqdm(range(len(ablation))):\n",
    "    if not os.path.exists('data/ablation_study/%s_%d_%d_%s/'%(ablation[i][0], ablation[i][1], ablation[i][2], ablation[i][3])):\n",
    "        os.makedirs('data/ablation_study/%s_%d_%d_%s/'%(ablation[i][0], ablation[i][1], ablation[i][2], ablation[i][3]))\n",
    "\n",
    "    img = cv2.imread(\"data\\\\shadows\\\\%s-%s\\\\16\\\\%d\\\\%d.png\"%(ablation[i][0], ablation[i][3], ablation[i][1], ablation[i][2]), cv2.IMREAD_GRAYSCALE)\n",
    "    height = cv2.imread(\"data\\\\heights_new\\\\%s\\\\16\\\\%d\\\\%d.png\"%(ablation[i][0], ablation[i][1], ablation[i][2]), cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    img = np.where(height > 0, 0, img)\n",
    "\n",
    "    plt.axis('off')\n",
    "    plt.imshow(img, cmap=_cmap);\n",
    "\n",
    "    plt.savefig('data/ablation_study/%s_%d_%d_%s/ground_truth.png'%(ablation[i][0], ablation[i][1], ablation[i][2], ablation[i][3]), bbox_inches='tight', pad_inches = 0)\n",
    "    plt.close();\n",
    "\n",
    "    saved_models = ['l1', 'l1_smooth', 'l2', 'ssim_l1', 'ssim_l1_smooth', 'ssim_sobel_plus_l1', 'ssim_with_sobel']\n",
    "    loss_functions = [[l1_loss], [l1_smooth_loss], [l2_loss], [ssim_loss, l1_loss], [ssim_loss, l1_smooth_loss], [ssim_loss, l1_loss, sobel_loss], [ssim_loss, sobel_loss]]\n",
    "\n",
    "    for j in range(len(saved_models)):\n",
    "        tf.keras.backend.clear_session()\n",
    "        down_stack, up_stack = get_generator_arch('resnet9', attn=False)\n",
    "        deep_shadow = DeepShadow(512, 512, down_stack, up_stack, latitude=True, date=True, loss_funcs=loss_functions[j], type='resnet9', attention=False)\n",
    "        deep_shadow.restore('training_checkpoints_new/uniform_cities_resnet_wo_attn__%s'%saved_models[j])\n",
    "\n",
    "        height, pred = predict_shadow(deep_shadow.generator, 'data/heights_new/', ablation[i][0], ablation[i][3], 16, ablation[i][1], ablation[i][2], lat=True, dat=True)\n",
    "        pred = np.where(height > 0, -1, pred)\n",
    "\n",
    "        plt.axis('off')\n",
    "        plt.imshow(pred, cmap=_cmap);\n",
    "\n",
    "        plt.savefig('data/ablation_study/%s_%d_%d_%s/%s.png'%(ablation[i][0], ablation[i][1], ablation[i][2], ablation[i][3], saved_models[j]), bbox_inches='tight', pad_inches = 0)\n",
    "        plt.close();\n",
    "        test_on_image(deep_shadow.generator, 'data/heights_new/', 'data/shadows/', ablation[i][0], ablation[i][3], 16, ablation[i][1], ablation[i][2], lat=True, dat=True,\n",
    "                      path = 'data/ablation_study/%s_%d_%d_%s/%s_metrics.png'%(ablation[i][0], ablation[i][1], ablation[i][2], ablation[i][3], saved_models[j]),\n",
    "                    save=True)\n",
    "    \n",
    "    # *** #\n",
    "\n",
    "    tf.keras.backend.clear_session()\n",
    "    down_stack, up_stack = get_generator_arch('unet', attn=False)\n",
    "    deep_shadow = DeepShadow(512, 512, down_stack, up_stack, latitude=True, date=True, loss_funcs=[l1_loss], type='unet', attention=False)\n",
    "    deep_shadow.restore('training_checkpoints_new/uniform_cities_unet_wo_attn__l1')\n",
    "\n",
    "    height, pred = predict_shadow(deep_shadow.generator, 'data/heights_new/', ablation[i][0], ablation[i][3], 16, ablation[i][1], ablation[i][2], lat=True, dat=True)\n",
    "    pred = np.where(height > 0, -1, pred)\n",
    "    \n",
    "    plt.axis('off')\n",
    "    plt.imshow(pred, cmap=_cmap);\n",
    "\n",
    "    plt.savefig('data/ablation_study/%s_%d_%d_%s/unet_l1.png'%(ablation[i][0], ablation[i][1], ablation[i][2], ablation[i][3]), bbox_inches='tight', pad_inches = 0)\n",
    "    plt.close();\n",
    "\n",
    "    test_on_image(deep_shadow.generator, 'data/heights_new/', 'data/shadows/', ablation[i][0], ablation[i][3], 16, ablation[i][1], ablation[i][2], lat=True, dat=True,\n",
    "                  path = 'data/ablation_study/%s_%d_%d_%s/unet_l1_metrics.png'%(ablation[i][0], ablation[i][1], ablation[i][2], ablation[i][3]),\n",
    "                save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "838e4804a9db4c23b0193a899ce8979c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83638c8a879d44ee8a6b4b631fe757db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1789 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "shadow_path = 'data/shadows/'\n",
    "height_path = 'data/heights_new/'\n",
    "files = glob.glob('data/tile_heights/*.csv')\n",
    "\n",
    "def store_model_result(_loss_functions, _saved_model, i, j, city, gen_arch='resnet9'):\n",
    "    tf.keras.backend.clear_session()\n",
    "    down_stack, up_stack = get_generator_arch(gen_arch, attn=False)\n",
    "    deep_shadow = DeepShadow(512, 512, down_stack, up_stack, latitude=True, date=True, loss_funcs=_loss_functions, type=gen_arch, attention=False)\n",
    "    deep_shadow.restore('training_checkpoints_new/%s'%_saved_model)\n",
    "\n",
    "    seasons = ['summer', 'winter', 'spring']\n",
    "    rmse = 0\n",
    "    for season in seasons:\n",
    "\n",
    "        # generator, height_path, city, date, zoom, i, j, lat=True, dat=True\n",
    "        height, pred = predict_shadow(deep_shadow.generator, 'data/heights_new/', city, season, 16, i, j, lat=True, dat=True)\n",
    "        pred = np.where(height > 0, -1, pred)\n",
    "\n",
    "        gt = load_ground_truth(height, shadow_path, city, season, 16, i, j)\n",
    "        gt = np.where(height > 0, -1, gt)\n",
    "\n",
    "        pred = pred*0.5 + 0.5\n",
    "        gt = gt*0.5 + 0.5\n",
    "\n",
    "        rmse += np.sqrt(np.mean((pred - gt)**2))\n",
    "                \n",
    "    rmse /= 3\n",
    "\n",
    "    return rmse\n",
    "\n",
    "for file in tqdm(files, total=len(files), leave=False):\n",
    "    file = file.replace('\\\\','/')\n",
    "    tiles = pd.read_csv(file)\n",
    "    city = file.split('/')[-1].split('.')[0].split('-')[0]\n",
    "\n",
    "    # iter tiles df\n",
    "    rmses = []\n",
    "    for index, row in tqdm(tiles.iterrows(), total=tiles.shape[0], leave=False):\n",
    "        # get i, j\n",
    "        i = int(row['i'])\n",
    "        j = int(row['j'])\n",
    "\n",
    "        rmse_resnet = store_model_result([l1_loss], 'uniform_cities_resnet_wo_attn__l1', i, j, city, gen_arch='resnet9')\n",
    "        rmses.append(rmse_resnet)\n",
    "\n",
    "        rmse_unet = store_model_result([l1_loss], 'uniform_cities_unet_wo_attn__l1', i, j, city, gen_arch='unet')\n",
    "        rmses.append(rmse_unet)\n",
    "\n",
    "        # check if resnet is better than unet\n",
    "        if rmse_resnet < rmse_unet:\n",
    "            # print('resnet better than unet: ', city, i, j, rmse_resnet, rmse_unet)\n",
    "            # instead of printing write to file: data/model_comparison.txt\n",
    "            with open('data/resnet_better_unet.txt', 'a') as f:\n",
    "                f.write('%s %d %d %f %f\\n'%(city, i, j, rmse_resnet, rmse_unet))\n",
    "\n",
    "\n",
    "        saved_models = ['l1_smooth', 'l2', 'ssim_l1', 'ssim_l1_smooth', 'ssim_with_sobel']\n",
    "        loss_functions = [[l1_smooth_loss], [l2_loss], [ssim_loss, l1_loss], [ssim_loss, l1_smooth_loss], [ssim_loss, sobel_loss]]\n",
    "\n",
    "        for k in range(len(saved_models)):\n",
    "            _saved_model = 'uniform_cities_resnet_wo_attn__%s'%saved_models[k]\n",
    "            rmse = store_model_result(loss_functions[k], _saved_model, i, j, city, gen_arch='resnet9')\n",
    "            rmses.append(rmse)\n",
    "\n",
    "        rmse_ssim_sobel_l1 = store_model_result([ssim_loss, sobel_loss, l1_loss], 'uniform_cities_resnet_wo_attn__ssim_sobel_plus_l1', i, j, city, gen_arch='resnet9')\n",
    "\n",
    "        # check if rmse_ssim_sobel_l1 is the best among all\n",
    "        if rmse_ssim_sobel_l1 < min(rmses):\n",
    "            # print('resnet ssim_sobel_l1 best: ', city, i, j, rmse_ssim_sobel_l1, min(rmses))\n",
    "            # instead of printing write to file: data/model_comparison.txt\n",
    "            with open('data/ssim_sobel_l1_best.txt', 'a') as f:\n",
    "                f.write('%s %d %d %f %f\\n'%(city, i, j, rmse_ssim_sobel_l1, min(rmses)))\n",
    "            \n",
    "\n",
    "    # tiles.to_csv('data/tile_heights/%s-16_new.csv'%city, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the columns to shorter names and then again save to csv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
