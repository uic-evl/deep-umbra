{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pathlib\n",
    "import time\n",
    "import itertools\n",
    "import glob\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython import display\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from generatorSpatial import *\n",
    "from discriminatorSpatial import *\n",
    "from loss import *\n",
    "from utilsSpatial import *\n",
    "\n",
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "city = 'nyc'\n",
    "date = 'dec-21'\n",
    "zoom = 15\n",
    "shadow_path = 'e://Dropbox/vgc//shadow-slippy-vis//www//assets//%s-%s//'%(city,date)\n",
    "height_path = 'data/%s-heights/'%(city)\n",
    "checkpoint_path = './training_checkpoints/%s-%s'%(city,date)\n",
    "\n",
    "# Training size\n",
    "BUFFER_SIZE = 400\n",
    "\n",
    "#TODO load latitude matrix\n",
    "latitude_matrix = (np.ones((IMG_WIDTH,IMG_HEIGHT)) * 40.74510928549375) / 90\n",
    "latitude_matrix = tf.reshape(tf.convert_to_tensor(latitude_matrix, dtype=tf.float32), (1, 256, 256, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp, real = loadSpatial(height_path, shadow_path, zoom, 9655, 12306)\n",
    "\n",
    "# Casting to int for matplotlib to display the images\n",
    "plt.figure()\n",
    "plt.imshow(inp / 255.0)\n",
    "plt.figure()\n",
    "plt.imshow(real / 255.0)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "for i in range(4):\n",
    "    rj_inp, rj_re = random_jitter(inp, real)\n",
    "    plt.subplot(2, 2, i + 1)\n",
    "    plt.imshow(rj_inp / 255.0)\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "down_model = downsample(3, 4)\n",
    "down_result = down_model(tf.expand_dims(inp, 0))\n",
    "print (down_result.shape)\n",
    "\n",
    "up_model = upsample(3, 4)\n",
    "up_result = up_model(down_result)\n",
    "print (up_result.shape)\n",
    "\n",
    "generator = GeneratorSpatial()\n",
    "tf.keras.utils.plot_model(generator, show_shapes=True, dpi=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_output = generator([inp[tf.newaxis, ...], latitude_matrix], training=False)\n",
    "plt.imshow(gen_output[0, ...])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator = DiscriminatorSpatial()\n",
    "tf.keras.utils.plot_model(discriminator, show_shapes=True, dpi=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disc_out = discriminator([inp[tf.newaxis, ...], gen_output, latitude_matrix], training=False)\n",
    "plt.imshow(disc_out[0, ..., -1], vmin=-1, vmax=1, cmap='RdBu_r')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizers and a checkpoint-saver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_prefix = os.path.join(checkpoint_path, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
    "                                 discriminator_optimizer=discriminator_optimizer,\n",
    "                                 generator=generator,\n",
    "                                 discriminator=discriminator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, test_dataset = get_train_test_spatial(height_path, shadow_path, city, date, zoom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for example_input, example_target in test_dataset.take(5):\n",
    "    generate_images(generator, example_input, latitude_matrix, example_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir=\"logs/\"\n",
    "\n",
    "summary_writer = tf.summary.create_file_writer(log_dir + \"fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(input_image, target, latitude_matrix, step):\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        #gen_output = generator(input_image, training=True)\n",
    "        gen_output = generator([input_image, latitude_matrix], training=True)\n",
    "\n",
    "        #disc_real_output = discriminator([input_image, target], training=True)\n",
    "        disc_real_output = discriminator([input_image, target, latitude_matrix], training=True)\n",
    "        #disc_generated_output = discriminator([input_image, gen_output], training=True)\n",
    "        disc_generated_output = discriminator([input_image, gen_output, latitude_matrix], training=True)\n",
    "\n",
    "        gen_total_loss, gen_gan_loss, gen_l1_loss = generator_loss(disc_generated_output, gen_output, target)\n",
    "        disc_loss = discriminator_loss(disc_real_output, disc_generated_output)\n",
    "        \n",
    "\n",
    "    generator_gradients = gen_tape.gradient(gen_total_loss,\n",
    "                                          generator.trainable_variables)\n",
    "    discriminator_gradients = disc_tape.gradient(disc_loss,\n",
    "                                               discriminator.trainable_variables)\n",
    "\n",
    "    generator_optimizer.apply_gradients(zip(generator_gradients,\n",
    "                                          generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(discriminator_gradients,\n",
    "                                              discriminator.trainable_variables))\n",
    "\n",
    "    with summary_writer.as_default():\n",
    "        tf.summary.scalar('gen_total_loss', gen_total_loss, step=step//1000)\n",
    "        tf.summary.scalar('gen_gan_loss', gen_gan_loss, step=step//1000)\n",
    "        tf.summary.scalar('gen_l1_loss', gen_l1_loss, step=step//1000)\n",
    "        tf.summary.scalar('disc_loss', disc_loss, step=step//1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(train_ds, test_ds, latitude_matrix, steps):\n",
    "    example_input, example_target = next(iter(test_ds.take(1)))\n",
    "    start = time.time()\n",
    "\n",
    "    for step, (input_image, target) in train_ds.repeat().take(steps).enumerate(): \n",
    "        if (step) % 1000 == 0:\n",
    "            display.clear_output(wait=True)\n",
    "\n",
    "            if step != 0:\n",
    "                print(f'Time taken for 1000 steps: {time.time()-start:.2f} sec\\n')\n",
    "\n",
    "            start = time.time()\n",
    "            \n",
    "            #generate_images(generator, example_input, example_target)\n",
    "            generate_images(generator, example_input, latitude_matrix, example_target)\n",
    "            print(f\"Step: {step//1000}k\")\n",
    "\n",
    "        #train_step(input_image, target, step)\n",
    "        train_step(input_image, target, latitude_matrix, step)\n",
    "\n",
    "        # Training step\n",
    "        if (step+1) % 10 == 0:\n",
    "            print('.', end='', flush=True)\n",
    "\n",
    "\n",
    "        # Save (checkpoint) the model every 5k steps\n",
    "        if (step + 1) % 5000 == 0:\n",
    "            checkpoint.save(file_prefix=checkpoint_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir {log_dir} --port 8088"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit(train_dataset, test_dataset, latitude_matrix, steps=40000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "# for example_input, example_target in test_dataset.take(5):\n",
    "#     generate_images(generator, example_input, latitude_matrix, example_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmses = []\n",
    "for filename in test_dataset_check:\n",
    "    test_input, test_target = load_image_test_spatial(filename)\n",
    "    prediction = generator([test_input[tf.newaxis, ...], latitude_matrix], training=True)\n",
    "    \n",
    "    test_input = test_input.numpy()\n",
    "    test_target = test_target.numpy()\n",
    "    prediction = prediction.numpy()\n",
    "    \n",
    "    test_input = test_input * 0.5 + 0.5\n",
    "    test_target = test_target * 0.5 + 0.5\n",
    "    prediction = prediction * 0.5 + 0.5\n",
    "    \n",
    "    rmse = np.sqrt(np.mean((prediction-test_target)**2))\n",
    "    rmses.append(rmse)\n",
    "    \n",
    "#     plt.figure(figsize=(15, 15))\n",
    "#     plt.subplot(1, 2, 1)\n",
    "#     plt.title('Target')\n",
    "#     plt.imshow(test_target[0,:,:,:])\n",
    "#     plt.axis('off')\n",
    "    \n",
    "#     plt.subplot(1, 2, 2)\n",
    "#     plt.title('Prediction')\n",
    "#     plt.imshow(prediction[0,:,:,:])\n",
    "#     plt.axis('off')\n",
    "    \n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.average(rmses)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
